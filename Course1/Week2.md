# 前言

<p>当在网络中组织计算的时候，经常使用所谓的前向传播，以及反向传播，所以将会了解为什么在训练神经网络时，计算可以被正向传播组织为一次前向传播过程以及一次反向传播过程</p>

# 二元分类

<p>逻辑回归是一个二元分类算法</p>

<p>这里有一个二元分类问题的例子：有一张输入照片，希望算法输出一个 0 或 1 的 label 指明图上是不是猫。用符号 y 来表示输出标签</p>

<p>先来看图像在计算机中如何表示：为了存储一张彩色图像，计算机要存储三个独立的矩阵，为了用向量表示，把矩阵的像素值展开为一个向量 x 作为算法的输入，得到一个非常长的向量，如 64 * 64 的，得到 64*64*3 = 12288。用 n_x = 12288 来表示输入特征向量 x 的维度</p>

<p>所以在二元分类的问题中，目标是学习到这样的一个分类器：输入一副以特征向量 x 表示的图像，然后预测对应的输出 y 是 1 还是 0</p>

<p>先介绍符号：</p>

- (x, y)表示单个样本，x 为 n_x 维的特征向量，y 是标签，取值 0 或 1

- m 表示样本集中单个样本的数量

<p>为了将所有的训练样本写成更加紧凑的形式，将定义一个矩阵，用 X 表示，大小是 n_x * m</p>

<p>Y = [y_1, y_2, ... , y_m]，1 * m</p>














