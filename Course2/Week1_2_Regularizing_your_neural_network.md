# Regularization

</br>

<p>如果你怀疑你的神经网络在数据上发生了过拟合（存在高方差问题），首先尝试使用正则化，获取更多数据也是一个可靠的方法，但不是总能获取数据</p>

</br>

## 逻辑回归

</br>

<p>以逻辑回归为例子进行阐述，在逻辑回归中，会尝试最小化代价函数 J：</p>

$$
J(w, b) = \frac{1}{m} \sum_{i = 1}^{m}L(\hat{y}^{(i)}, y^{(i)}) 
$$

<p>w 是 n_x 维的参数向量，b 是一个实数</p>

<p>要为逻辑回归正则化，需要加上 lambda，他称为正则化参数</p>

$$
J(w, b) = \frac{1}{m} \sum_{i = 1}^{m}L(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2m}{\|w\|_2}^2
$$

<p>其中：</p>

$$
{\|w\|_2}^2 = \sum_{j = 1}^{n_x}{w_j}^2 = w^T w 
$$

<p><b>这称为 L2 正则化</b>，其为 L2 范数</p>

<p>关于为何只对 w 进行正则化：事实上也可以加上 b 的范数，但通常会把他省略掉。</p>

<p>观察参数，w 往往是一个非常高维的参数矢量，尤其是发生在高方差问题的情况下，w 可能有非常多的参数。没能很好的拟合所有参数，而 b 只是单个数字，几乎所有参数都集中在 w 中，而不是 b。所以即使加上最后一项，也不会起到很大的作用（因为 b 只是大量参数中的一个）</p>

<p>L2 正则化是最常见的正则化方式</p>

<p>可能也听过 L1 正则化，即不使用 L2 范数，而是使用：</p>

$$
\frac{\lambda}{m}\sum_{j = 1}^{n_x}|w| = \frac{\lambda}{m}\|w\|_1
$$

<p>称为参数矢量 w 的 L1 范数（无论是 m 还是 2m 都只是一个缩放变量）</p>

<p>如果使用 L1 正则化，w 最后会变得稀疏，意味着 w 矢量中有很多 0。有人认为这有助于压缩模型，因为有一部分参数是 0，只需较少的内存来存储模型</p>

<p>在实践中发现，通过 L1 正则化让模型变得稀疏，带来的收益甚微，所以觉得至少在压缩模型的目标上他作用不大。</p>

<p>在训练神经网络时，L2 正则化使用得频繁很多</p>

<hr>

<p>lambda 被称为正则化参数，通常使用开发集或 hold-out 交叉验证，来配置参数。通过尝试一系列的值，找出最好的那个，即在“训练集上得到较好的结果”和“保持参数 w 的 L2 范数较小以避免过拟合”之间取舍</p>

<p>lambda 是你需要调优的另一个超参数</p>

<p>以上是在逻辑回归中实现 L2 正则化的方法</p>

</br>

## 神经网络

</br>

<p>在神经网络中，代价函数是所有参数的函数，w[1] b[1] 到 w[L] b[L]</p>

<p>至于正则化，再加上一项</p>

$$
J(w^{[1]}, b^{[1]}, ..., w^{[L]}, b^{[L]}) = \frac{1}{m}\sum_{i = 1}^{m}L(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2m}\sum_{l = 1}^{L}{\|w^{[l]}\|_F}^2
$$

$$
{\|w^{[l]}\|}^2 = \sum_{i = 1}^{n^{[l]}}\sum_{j = 1}^{n^{[l - 1]}}(w_{ij}^{[l]})^2
$$

<p>称为矩阵的弗罗贝尼乌斯范数</p>

</br>

## 实现梯度下降

</br>

<p>之前使用反向传播计算 dw，通过反向传播，能得到 J 关于 w 的偏导数</p>

$$
dW^{[l]} = (frombackprop)
$$

$$
W^{[l]} := W^{[l]} - \alpha dW^{[l]}
$$

<p>这是为目标函数添加正则化项之前的步骤，现在为目标函数添加了正则化项，就需要为 dw 加上一项</p>

$$
dW^{[l]} = (frombackprop) + \frac{\lambda}{m} W^{[l]}
$$

<p>可以证明，新的 dW[l] 仍然正确的定义了添加了额外的正则化项之后代价函数关于参数的导数</p>

<p>出于这个原因，L2 正则化有时也被称为权重衰减(Weight decay)</p>

<p>用新的 dw[l] 进行更新</p>

$$
W^{[l]} := (1 - \frac{\alpha \lambda}{m} )W^{[l]} - \alpha (frombackprop)
$$

<p>第一项(系数略小于 1)表示无论矩阵 W[l] 是多少，都会让他变得稍小一些，这就是 L2 范数正则化被称为权重衰减的原因</p>

</br>

# Why regularization reduces overfitting

![QQ_1745323720521](https://github.com/user-attachments/assets/f66e4202-400b-4c5a-a2d2-9b8a01601c03)

<p>可以认为第三个就是过拟合的神经网络</p>

<p>正则化所做的是添加一些额外的项目</p>

$$
J(W^{[l]}, b^{[l]}) = \frac{1}{m} \sum_{i = 1}^{m} L(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2m}\sum_{l = 1}^{L}{\|w^{[l]}\|_F}^2
$$

<p>关于为何通过参数项就能减轻过拟合情况，一个直观理解就是，如果把正则参数 lambda 设置的很大，权重矩阵 W 就会被设置为非常接近 0 的值。因此这个直观理解就是把很多隐藏单元的权重设置的太接近 0 了而导致这些隐藏单元的影响被消除了</p>

![QQ_1745325149803](https://github.com/user-attachments/assets/de14b23a-b03b-48c3-9b31-014cccd7acaa)

<p>如果是这种情况，那么就会使这个大大简化的神经网络变成一个很小的神经网络，实际上，这种情况与逻辑回归单元很像，但很可能是网络的深度更大了，因此这就会使这个过拟合网络被带到更接近左图高偏差的状态。但是 lambda 存在一个中间值，能够得到一个更加接近中间图这个刚好的状态的</p>

<p>直观理解就是把 lambda 值设的足够高的话，他就会使 W 接近 0。但实际上不会发生这种情况，我们可以想象成通过把隐藏单元的值归零来削减了隐藏单元的影响，最终导致这个网络变成了一个更加简单的网络（越来越接近逻辑回归）</p>

<p>直觉上认为这些隐藏单元的影响被完全消除了，其实并不正确，实际上网络仍在使用所有的隐藏单元，但每个隐藏单元的影响变的非常小了，<b>最终得到的网络看起来就像一个不容易过拟合的小型的网络</b></p>

<hr>

<p>来看另一个例子来理解为什么正则化可以帮助防止过拟合</p>

<p>假设使用的激活函数是 tanh(z)</p>

<p>可以发现只要 z 的绝对值很小，比如 z 只涉及很小范围的参数</p>

![QQ_1745326279231](https://github.com/user-attachments/assets/32ba2f95-69a7-4409-83a9-f199f9eb3822)

<p>那么其实是在使用 tanh 函数的线性部分，当 z 的值能够取到很大或者很小的时候，激活函数才开始展现出他的非线性能力</p>

<p>因此直觉就是，如果 lambda 被设置的很大的话，那么激活函数的参数实际上就会变小（因为代价函数的参数会被限制导致不能过大），如果 w 变小，z 也会变小，特别是 z 的值相对都很小的时候，那么 tanh(z) 函数就会接近于线性函数。因此，每一层都几乎是线性的（就像线性回归一样）。</p>

<p>之前说过<b>如果每层都是线性的，那么整个网络就是线性网络。因此即使是一个很深的神经网络，如果使用线性激活函数，最终也只能计算线性的函数，因此就不能拟合那些很复杂的决策函数，也不能过度拟合那些数据集的非线形决策平面</b>，就像前面看到的过拟合高方差的情况</p>

![QQ_1745326835051](https://github.com/user-attachments/assets/e86228d7-0e0b-450f-aa46-04b6dbc5c931)

<p>总结：如果正则化(lambda)变得非常大，参数 W 就会很小，那么 Z 就会相对变小，即 z 只在小范围内取值（此时先忽略 b 的影响）。那么激活函数如果是 tanh 的话，这个激活函数就会呈现相对线性，那么整个神经网络就只能计算一些离线形函数很近的值，也就是相对比较简单的函数，而不能计算很复杂的非线性函数，因此就不太容易过拟合了（你会亲眼看到的）</p>

<p>以上就是 L2 正则化，也是我训练深度模型时最常用的正则化技巧，有时也会用到 drop-out 正则化</p>











































































































































































































































































































































































































































































































































































