</br>

# Normalizing inputs

</br>

<p>训练神经网络时，加快训练速度的方法之一是<b>对输入进行归一化</b></p>

<p>例举这个包含两个输入特征的训练集，如下为其散点图</p>

![QQ_1745561153396](https://github.com/user-attachments/assets/67ac959a-9643-453d-a396-e2712f9b2897)

<p>对输入进行归一化对应于两个步骤：</p>

<p>第一步是减去均值或归零</p>

<p>Subtrack mean(中心化):</p>

$$
\mu = \frac{1}{m} \sum_{i = 1}^{m}x^{(i)}
$$

$$
x := x - \mu
$$

![QQ_1745563241934](https://github.com/user-attachments/assets/d8543ae0-d3f5-4d06-b505-38f5c40953d3)

<hr>

<p>第二步是对方差进行归一化</p>

<p>此处的 feature x1 的方差比特征 x2 大得多。</p>

<p>Normalize variance(归一化):</p>

$$
\sigma^2 = \frac{1}{m} \sum_{i = 1}^{m} {x^{(i)}}^2
$$

$$
x = \frac{x}{\sigma}
$$

![QQ_1745564422812](https://github.com/user-attachments/assets/d3d8dc24-6d37-4c58-a9f7-bb1d83add9b5)

<p>得到这样的结果，现在 x1 和 x2 的方差都是 1</p>

<p>tip：如果使用它来缩放训练数据，则使用相同的 mu 和 sigma 来归一化测试集。特别是，你不想以不同的方式对训练集和测试集进行归一化。不管 mu 和 sigma 的值是什么，都要在 `x = \frac{x}{\sigma}` 和 `x := x - \mu` 这两个公式中使用它们，这样就可以用完全相同的方式缩放测试集，而不是分别估算测试集和训练集上的 mu 和 sigma square</p>

</br>

## 为什么要进行归一化

</br>

<p>事实证明，如果使用非标准化的输入特征，成本函数更有可能看起来如下这样，非常细长的成本函数</p>

![QQ_1745566222068](https://github.com/user-attachments/assets/eafc347e-fcb3-4860-b5ed-0aaa383bdb8f)

<p>如果特征比例截然不同，比如 x1 的范围是 1-1000，x2 的范围是 0-1，那么事实证明 w1(对应 x1) 和 w2(对应 x2) 的比率或值范围将采用截然不同的值</p>

<p>如果对 features 进行归一化，成本函数平均看起来会更加对称</p>

![QQ_1745566325251](https://github.com/user-attachments/assets/055ebda8-c385-44b1-b6f9-54c6c4c85df0)

<p>如果在 Unnormalized 成本函数上运行梯度不错，那么可能需要使用非常小的学习率，因为梯度可能需要很多步骤来回震荡才能达到最小值</p>

![QQ_1745566934752](https://github.com/user-attachments/assets/536532df-1d92-4492-b343-eb36e3a51787)

<p>当你的 feature 规模相似时，粗略的直觉是，成本函数会更加全面，更加容易优化</p>
 
<p>对于多特征来说，将他们全部设置为零均值，并设置方差为 1，就可以保证所有 feature 都处于相似的比例，帮助学习算法更快的运行</p>

<p>总结：如果 feature 来自截然不同的比例（0-1 和 1-1000），那么对 feature 进行归一化非常重要。如果 feature 以相似的比例出现，那么就不重要了</p>

</br>

# Vanishing/exploding gradients 

</br>

<p>当训练神经网络时会遇到一个问题----梯度的消失和爆炸，<b>尤其是训练层数非常多的神经网络时</b>。意思是当在训练一个深度神经网络时，损失函数的导数有时会变得非常大或非常小，这使得训练变得很困难</p>

<p>讨论梯度爆炸和消失的含义，以及如何谨慎的选择随机初始化的权重来显著减少这种问题的发生</p>

<p>假设正在训练一个层数很多的神经网络，会有参数 W[1],W[2],...W[l]，为了简单起见，设置 g(z) = z*（一个线性的激活函数），忽略 b</p>

<p>在这种情况下，Y hat = W[L] W[L - 1] ... W[2] W[1] x</p>

<p>所以如果神经网络的层数很多，Y 的值可能会爆炸(比如 W 是 1.5 倍的单位矩阵)，也可能会消失（0.5 倍的单位矩阵，变为 1/2 的 L 次）</p>

<p>对于权重系数 W，如果他们仅比单位矩阵大一些，那么在一个很深的网络，激活函数可能就会爆炸；如果他们仅比单位矩小一些，激活函数就会指数级的减少</p>

<p>在这么深的神经网络里，如果激活函数或梯度作为 L 的函数指数级的增加或减少，这些纸会变得很大或很小，这会让训练变得很困难。尤其是如果梯度比 L 要小指数级别，梯度下降会用很小很小的步走，会用比较长的时间学习</p>

</br>

# Weight initialization for deep network

</br>

<p>有一种针对此问题的部分解决方法，虽然不能完全解决，但帮助很大。该方法就是更好更细致地随机初始化你的神经网络</p>

<p>为了理解这个方法，从初始化单个神经元开始，再应用到深度网络中</p>

`z = w1 x1 + w2 x2 + ... + wn xn //忽略 b`

<p>为了不让 z 项太大或者太小，n 项（输入的特征数）的数值越大，就会希望 wi 的值越小</p>

<p>一个合理的做法是，让 wi 等于 1/n  </p>

`W[l] = np.random.randn(shape) * np.sqrt(1 / n[l - 1])`

<p>如果使用 reLu 函数，就用 2/n</p>

<p>所以，如果输入经过激活函数的 feature 平均值为 0 并且标准差为 1，这就能使 z 项也呈现相同的分布性质。虽然不能完全解决问题，但降低了梯度消失和梯度爆炸的程度。因为通过设置权重矩阵，使得 W 不会比 1 大很多，也不会比 1 小很多，因此梯度不会过快的膨胀或消失</p>

<p>刚刚描述的是使用 ReLU 作为激活函数，讲讲其他变体，使用 tanh 时，与使用 2 作为常数项不同，使用 1 作为常数项更好</p>

<p>这就是 Xavier 初始化方法</p>

<p>另一些也会用到这个 np.sqrt(2 / (n[l - 1] * n[l]))</p>

<p>在实践中，这些所有公式只是给你一个出发点，他让权重矩阵的初始化变量有一个默认值</p>

<p>这些变量参数可以成为超参数的一部分，可以通过调优确定使用哪个版本，<b>调优这个乘数作为超参数的一部分，有时调优这个超参数会影响模型的规模</b>，通常不是要最先调优的超参数之一</p>

<p>summary：如果使用适合的方法去初始化权重，这些能使你的权重和梯度不会过快的爆炸或者消失，</p>

</br>

# Numerical approximation of gradients(梯度的数值逼近)

</br>

<p>当实现梯度逆传播时，会发现一个测试叫做名叫梯度检验，可以帮你确保你的梯度逆传播的实现是正确的</p>

<p>为了介绍梯度检验，先讨论如何在数值上近似计算梯度</p>

<p>双侧差值用在梯度检验和逆传播时，运行起来很可能比用单侧差值要慢两倍，但从实践的角度值得一用，因为他精确很多</p>

<p>也没什么好说的其实</p>

</br>

# Gradient Checking

</br>

<p>讨论怎么用梯度检查来调试代码，并检验反向传播代码</p>

<p>把参数 W[1], b[1], W[2], b[2], ..., W[l], b[l] 首尾相接拼接成一个向量 theta，代价函数变为 J(theta)，dtheta 变为 J 的梯度</p>

<p>接下来就是编写梯度检查算法</p>

<p>实现梯度检查算法时，首先要写一个循环</p>

```
for each i:
  d\theta_{approx}^{[i]} = \frac{J(\theta_1, \theta_2, ..., \theta_i + \xi, ...) - J(\theta_1, \theta_2, ..., \theta_i + \xi, ...)}{2\xi}
```

$$
d\theta_{approx}^{[i]} = \frac{J(\theta_1, \theta_2, ..., \theta_i + \xi, ...) - J(\theta_1, \theta_2, ..., \theta_i + \xi, ...)}{2\xi}\approx
 d\theta^{[i]}
$$

<p>把 theta 的所有分量都按这个方法计算一遍，得到两个向量 dtheta_approx 和 dtheta，要检查这两个向量是否大致相等</p>

<p>关于如何定义两个向量好似大致相等：计算两个向量的欧几里得距离</p>

<p>求两个向量的每个分量的差的平方之和在开方就是欧几里得距离，再把结果根据向量的长度标准化（把他除以向量 dtheta_approx 和 dtheta 的欧几里得长度的和）</p>

$$
\frac{\|d\theta_{approx} - d\theta\|_2}{\|d\theta_{approx}\|_2 + \|d\theta\|_2}
$$

<p>除以该分母是为了防止这两个向量太小或太大</p>

<p>在实际中，我去 xi 为 1e-7，这样，如果这个式子的值小于 1e-7 就认为是计算正确，表示微分近似是正确的（因为误差很小），如果是 1e-5 就会仔细的检查一遍，因为也有可能是对的</p>

</br>

# Gradient Checking implementation notes

</br>

<p>展示一些实用技巧</p>

<p>首先，不要在训练中使用梯度检查，仅仅在调试时使用。计算 dtheta_approx_i 是一个很慢的过程，所以当运用梯度下降时，会用反向传播来计算 dtheta，所以在调试时才会需要计算这个，来保证与 dtheta 足够接近</p>

<p>当完成后，需要关掉梯度检验，别在每一次进行梯度下降迭代的时候，都运行梯度检验，否则会很慢</p>

<hr>

<p>如果一个算法没有通过梯度检验，需要检查他的组成，检查每一个组成成分，尝试找出漏洞。</p>

<p>检查不同的 i 值，看看那些 dthetaapprox 与 dtheta 差距过大。举个例子，如果发现某个 dtheta 差距过大，可能与这一层的或某些层的 db[l] 有关，也许能帮你找到漏洞的位置</p>

<hr>

<p>当进行梯度检验时，如果使用了正则化，别忘了正则项</p>

$$
J(\theta) = \frac{1}{m} \sum_{i = 1}^{m} L(\hat{y}^{(i)}, y^{(i)}) + \frac{\lambda}{2m} \sum_{j = 1}^{L}{\|W^{[l]}\|^2_F}
$$

`dtheta = grad of J with theta`

<hr>

<p>梯度检验不能与随机失活(dropout)一起使用，因为在每一次迭代中，随机失活将随机消除隐藏层单元的不同子集</p>

<p>在使用随机失活进行梯度下降的过程中，并不存在一个容易计算的代价函数 J。随机失活可以被视作对于代价函数的优化</p>

<p>用梯度检验来检查，包含了随机失活的运算时很困难的。可以把 keep.prob 设为 1.0</p>

<hr>

<p>Run at random initialization;perhaps again after some training</p>

<P>在网络刚初始化（参数是随机的）的时候，做一次梯度检查（Gradient Check）确认反向传播没错；训练一段时间后，也可以再做一次，确保训练过程中反向传播仍然正确。</P>

<p>W 和 b 在随机初始化的时候，是很接近 0 的数，但随着梯度下降的进行，W 和 b 有所增大。也许你的反向传播算法在接近 0 的时候是正确的，但当 W 和 b 变大的时候，精确度有所下降</p>

-	刚初始化时检查：最保险，因为那时候参数是随机的，能覆盖各种数值情况（正的、负的、小数、大数），如果梯度没问题，说明你的反向传播代码一开始就没写错。

-	训练一段时间后再检查：训练过程中参数会逐渐有规律（比如越来越小、越来越接近局部极值），这个时候梯度变化可能变得很敏感，所以也可以检查一下确保没有因为数值稳定性的问题导致出错。

</br>

# Week1 summary

</br>

<p>学习了如何设置训练，开发，测试集。如何分析高偏差/高方差，以及如何面对高偏差和高方差。如何应用不同形式的正则化，比如 L2 正则化，和对你的神经网络进行随机失活。即一些加速神经网络训练的技巧。最后是梯度检验的内容</p>


















































































































































































































































































































































































































